---
date: 2024-05-20
order: 7
title: "Learning Transferable Visual Models From Natural Language Supervision"
url: /papers-in-public/clip
anchor: clip
paper_url: https://arxiv.org/abs/2103.00020
video_url: https://www.youtube.com/embed/-9NQTy840i0?si=wuHQFroTlXr1RBAr
description: |
  <p>Very impactful 2021 paper from OpenAI showing how to train multimodal (text + image) embedding spaces. Learns image and text representations that allow predicting which text captions match which images.</p>

  <p>It turns out that by doing this at sufficiently large scale, you end up training a model that does pretty well at other tasks, so it probably learns useful representations of both texts and images.</p>

  <p>Big, detailed paper, so I can't do it justice in 5 minutes - this overview is mostly the context around it and only the very core of the idea behind the model.</p>
---
